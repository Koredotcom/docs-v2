# Prompt Studio

Design, test, and optimize prompts across multiple models.

---

## Overview

Prompt Studio transforms prompt engineering from guesswork into a systematic process. Test prompts across different models, compare results side-by-side, and identify the optimal configuration for your use case.

```
Design Prompt → Add Variables → Select Models → Run Tests → Compare Results → Deploy
```

---

## Key Features

- **Multi-model comparison**: Test up to 5 models simultaneously
- **Variable support**: Batch process prompts with different inputs
- **65+ templates**: Pre-built prompts for common use cases
- **Version control**: Track prompt iterations
- **JSON schemas**: Structure model outputs
- **Dataset import**: Load test data from CSV files

---

## Workflow

### 1. Create a Prompt

Start with one of three approaches:

**Generate**: Describe what you want and let AI expand it into a detailed prompt.

**From scratch**: Write your prompt manually with full control.

**From library**: Use a pre-built template as a starting point.

### Prompt Structure

```markdown
# System Prompt (optional)
You are a helpful customer service agent for an e-commerce company.
Be concise, professional, and friendly.

# Human Prompt
Customer inquiry: {{inquiry}}
Order history: {{order_history}}

Please provide a helpful response addressing their concern.
```

---

### 2. Define Variables

Variables enable testing with different inputs.

**Syntax**: `{{variable_name}}`

**Example**:
```markdown
Summarize this product review:

Product: {{product_name}}
Review: {{review_text}}
Rating: {{rating}}/5
```

**Variable sources**:
- Manual entry
- CSV import
- AI-generated test data

---

### 3. Select Models

Compare performance across models:

| Provider | Available Models |
|----------|-----------------|
| OpenAI | GPT-4, GPT-4o, GPT-3.5-turbo |
| Anthropic | Claude 3 Opus, Sonnet, Haiku |
| Google | Gemini 1.5 Pro, Flash |
| Azure | GPT-4, GPT-3.5-turbo |
| Custom | Fine-tuned models |

### Model Parameters

Adjust settings per model:

```yaml
temperature: 0.7      # Creativity (0-1)
top_p: 0.9           # Nucleus sampling
top_k: 50            # Token selection
max_tokens: 1000     # Output length
```

---

### 4. Run Tests

Click **Run** to execute prompts across selected models.

**Batch processing**: Run up to 10 data rows simultaneously.

**Results include**:
- Generated response
- Tokens sent/received
- Response time
- Cost estimate

---

### 5. Compare Results

Evaluate models across dimensions:

| Criteria | Description |
|----------|-------------|
| **Accuracy** | Factual correctness |
| **Relevance** | Addresses the prompt |
| **Tone** | Appropriate style |
| **Completeness** | Thorough coverage |
| **Latency** | Response speed |
| **Cost** | Token economics |

---

## JSON Schema Output

Structure model responses with schemas:

### Definition

```json
{
  "type": "object",
  "properties": {
    "sentiment": {
      "type": "string",
      "enum": ["positive", "negative", "neutral"]
    },
    "confidence": {
      "type": "number",
      "minimum": 0,
      "maximum": 1
    },
    "key_topics": {
      "type": "array",
      "items": { "type": "string" }
    }
  },
  "required": ["sentiment", "confidence"]
}
```

### Result

```json
{
  "sentiment": "positive",
  "confidence": 0.92,
  "key_topics": ["product quality", "fast shipping", "customer service"]
}
```

---

## Test Data

### Import from CSV

Upload a CSV with columns matching your variables:

```csv
product_name,review_text,rating
"Wireless Headphones","Great sound quality!",5
"Phone Case","Broke after a week",2
"Laptop Stand","Sturdy and adjustable",4
```

### Generate Synthetic Data

Let AI create test data:

1. Define your prompt with variables
2. Click **Generate test data**
3. AI analyzes context and generates appropriate values
4. Review and edit as needed

---

## Prompt Library

Access 65+ pre-built templates:

### Categories

- **Content generation**: Blog posts, emails, marketing copy
- **Summarization**: Documents, meetings, articles
- **Analysis**: Sentiment, classification, extraction
- **Code**: Generation, explanation, debugging
- **Customer service**: Responses, FAQs, escalation
- **Data**: Formatting, transformation, validation

### Using Templates

1. Browse the library by category
2. Preview template content
3. Click **Use template**
4. Customize for your use case

---

## Version Control

Track prompt evolution:

```
v1.0 - Initial prompt
v1.1 - Added tone guidelines
v1.2 - Improved error handling
v2.0 - Restructured for better accuracy
```

### Best Practices

- Document changes in version notes
- Test before promoting to production
- Keep previous versions for rollback

---

## Integration

### Export to Tools

Deploy optimized prompts to:

- Agent instructions
- AI nodes in workflow tools
- Code tool prompts

### API Access

Use prompts programmatically:

```javascript
const response = await client.prompts.execute({
  promptId: "prompt_123",
  variables: {
    inquiry: "Where is my order?",
    order_history: orderData
  },
  model: "gpt-4o"
});
```

---

## Best Practices

### Be Specific

```markdown
# Vague
Summarize this text.

# Specific
Summarize this customer support ticket in 2-3 sentences.
Focus on: the issue, attempted solutions, and current status.
Format as bullet points.
```

### Provide Examples

```markdown
Classify the sentiment of this review.

Examples:
- "Love this product!" → positive
- "Worst purchase ever" → negative
- "It's okay, nothing special" → neutral

Review: {{review_text}}
Sentiment:
```

### Use System Prompts

Set consistent behavior:

```markdown
# System
You are a technical documentation writer.
- Use clear, concise language
- Include code examples where helpful
- Avoid jargon unless necessary
```

### Test Edge Cases

Include challenging inputs:

- Empty values
- Very long text
- Special characters
- Ambiguous requests

---

## Related

- [Evaluation Studio](/evaluation)
- [Agents](/agents)
- [AI Nodes](/tools/nodes#ai-nodes)
- [Models](/models)

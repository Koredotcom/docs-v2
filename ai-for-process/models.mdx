# Model Hub

Deploy and manage AI models for workflow automation.

---

## Overview

Model Hub provides centralized AI model management:

- **Open-source models** — Access Hugging Face and custom models
- **External providers** — Connect OpenAI, Anthropic, Google
- **Fine-tuned models** — Train models on your data
- **Model versioning** — Track and deploy model versions

---

## Model Types

### Open-Source Models

Access models from Hugging Face and other sources:

| Category | Examples |
|----------|----------|
| **Text generation** | Llama 2, Mistral, Falcon |
| **Embeddings** | BGE, E5, Instructor |
| **Classification** | BERT, RoBERTa |
| **Image** | Stable Diffusion, SDXL |

### External Models

Connect to cloud AI providers:

| Provider | Models |
|----------|--------|
| **OpenAI** | GPT-4, GPT-4o, GPT-3.5, DALL-E, Whisper |
| **Anthropic** | Claude 3 Opus, Sonnet, Haiku |
| **Google** | Gemini 1.5 Pro, Gemini 1.5 Flash |
| **Azure** | Azure OpenAI deployments |

### Fine-Tuned Models

Custom models trained on your data:

| Type | Use Case |
|------|----------|
| **Classification** | Custom categories |
| **Extraction** | Domain-specific entities |
| **Generation** | Brand voice, style |
| **Embeddings** | Domain-specific similarity |

---

## Adding Models

### Add External Provider

1. Navigate to **Models** → **External Models**
2. Click **Add Provider**
3. Configure:

```yaml
Provider: OpenAI
API Key: sk-...
Organization ID: org-... (optional)
Base URL: https://api.openai.com (default)
Models:
  - gpt-4
  - gpt-4o
  - gpt-3.5-turbo
  - text-embedding-3-small
```

### Add Open-Source Model

1. Navigate to **Models** → **Open-Source**
2. Click **Add Model**
3. Configure:

```yaml
Model: mistralai/Mistral-7B-Instruct-v0.2
Source: huggingface
Deployment:
  type: serverless | dedicated
  gpu: A100
  replicas: 1
```

### Import Custom Model

1. Navigate to **Models** → **Custom**
2. Click **Import Model**
3. Provide:
   - Model files (safetensors, GGUF, etc.)
   - Model configuration
   - Tokenizer files
   - Deployment settings

---

## Fine-Tuning

### Create Fine-Tune Job

1. Navigate to **Models** → **Fine-Tuning**
2. Click **Create Fine-Tune**
3. Configure:

```yaml
Fine-Tune Job:
  name: "Invoice Classifier v2"
  base_model: gpt-3.5-turbo
  training_data:
    source: dataset
    dataset_id: invoice-training-data
  validation_data:
    source: dataset
    dataset_id: invoice-validation-data
  hyperparameters:
    epochs: 3
    batch_size: 4
    learning_rate_multiplier: 1.0
```

### Prepare Training Data

Format training data:

```json
{
  "messages": [
    {"role": "system", "content": "You classify invoices."},
    {"role": "user", "content": "Invoice from Acme Corp for office supplies"},
    {"role": "assistant", "content": "Category: Office Supplies\nVendor Type: Supplier"}
  ]
}
```

### Monitor Training

Track fine-tuning progress:

| Metric | Description |
|--------|-------------|
| **Training loss** | Model learning progress |
| **Validation loss** | Generalization quality |
| **Epochs completed** | Training iterations |
| **Estimated time** | Time remaining |

### Deploy Fine-Tuned Model

After training completes:

1. Review training metrics
2. Test with sample inputs
3. Click **Deploy**
4. Select deployment target

---

## Model Configuration

### Model Settings

Configure model behavior:

```yaml
Model Settings:
  model_id: gpt-4
  parameters:
    temperature: 0.7
    max_tokens: 1000
    top_p: 1.0
    frequency_penalty: 0.0
    presence_penalty: 0.0
  timeout: 30s
  retry:
    count: 3
    delay: 1s
```

### Rate Limits

Set usage limits:

```yaml
Rate Limits:
  requests_per_minute: 100
  tokens_per_minute: 100000
  requests_per_day: 10000
  alert_threshold: 80%
```

### Cost Management

Track and control costs:

```yaml
Cost Management:
  budget:
    monthly: $1000
    alert_at: 80%
  tracking:
    by_workflow: true
    by_user: true
  limits:
    max_request_cost: $1
```

---

## Model Endpoints

### Create Endpoint

Expose models as API endpoints:

```yaml
Endpoint: invoice-classifier
Model: ft:gpt-3.5-turbo:acme:invoice-v2
Authentication: api_key
Rate limit: 100/minute
URL: https://api.kore.ai/models/invoice-classifier/v1
```

### Use Endpoint

```bash
curl -X POST https://api.kore.ai/models/invoice-classifier/v1/complete \
  -H "Authorization: Bearer $API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Classify this invoice: ...",
    "max_tokens": 100
  }'
```

---

## Integrations

### Hugging Face

Connect your Hugging Face account:

```yaml
Hugging Face Integration:
  api_key: hf_...
  organization: your-org
  sync_models: true
  auto_import:
    - pattern: "your-org/*"
```

### Weights & Biases

Track experiments with W&B:

```yaml
W&B Integration:
  api_key: ...
  project: ai-for-process
  entity: your-team
  log:
    - training_metrics
    - model_artifacts
    - predictions
```

### S3 / Cloud Storage

Store models in cloud storage:

```yaml
Storage Integration:
  provider: s3
  bucket: ai-models
  prefix: ai-for-process/
  credentials:
    access_key: ...
    secret_key: ...
```

---

## Supported Models

### Text Generation

| Model | Provider | Context |
|-------|----------|---------|
| GPT-4 | OpenAI | 128K |
| GPT-4o | OpenAI | 128K |
| Claude 3 Opus | Anthropic | 200K |
| Claude 3 Sonnet | Anthropic | 200K |
| Gemini 1.5 Pro | Google | 1M |
| Llama 2 70B | Open-source | 4K |
| Mistral 7B | Open-source | 32K |

### Embeddings

| Model | Provider | Dimensions |
|-------|----------|------------|
| text-embedding-3-small | OpenAI | 1536 |
| text-embedding-3-large | OpenAI | 3072 |
| BGE-large | Open-source | 1024 |
| E5-large-v2 | Open-source | 1024 |

### Image

| Model | Provider | Type |
|-------|----------|------|
| DALL-E 3 | OpenAI | Generation |
| Stable Diffusion XL | Open-source | Generation |
| GPT-4 Vision | OpenAI | Understanding |

### Audio

| Model | Provider | Type |
|-------|----------|------|
| Whisper | OpenAI | Transcription |
| Whisper-large-v3 | Open-source | Transcription |

---

## Related

- [Prompts](/ai-for-process/prompts)
- [Workflow Nodes](/ai-for-process/nodes)
- [Getting Started](/ai-for-process/getting-started)
